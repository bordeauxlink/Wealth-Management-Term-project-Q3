{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the domain selected in the previous question, along with all the available data from the dataset, conduct a new analysis of the data.  \n",
    "\n",
    "a. Formulate a new research question or hypothesis that can be answered using the data available in the survey. Hint: When formulating your new research question, consider exploring under-examined variables (e.g., demographic characteristics of financial planners, behavioral biases, etc.) or alternative outcome measures. You may also consider interacting client characteristics with planner characteristics to uncover new insights. \n",
    "\n",
    "b. Develop a conceptual or theoretical framework to address the question. Back your predictions with work from the literature and knowledge from the field.  \n",
    "\n",
    "c. For your main new empirical analysis, present your results in a table. Explain your methods (e.g., OLS, Probit, etc) and justify why they are applicable here (e.g Probit for binary data, OLS for continuous, etc). Additionally, the mean and standard deviation of all variables used in your analysis must be presented in one descriptive statistics table.  \n",
    "\n",
    "d. Interpret your results, explaining the significance of the estimated effects and whether they verify your hypothesis. Discuss possible explanations if the hypothesis is not verified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>debt_impute</th>\n",
       "      <th>income_impute</th>\n",
       "      <th>DIR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>580000</td>\n",
       "      <td>110000</td>\n",
       "      <td>5.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>295000</td>\n",
       "      <td>65000</td>\n",
       "      <td>4.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30000</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   debt_impute  income_impute       DIR\n",
       "0       580000         110000  5.272727\n",
       "1            0         200000  0.000000\n",
       "2       295000          65000  4.538462\n",
       "3        30000         150000  0.200000\n",
       "4            0         150000  0.000000"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"clean_all.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate Debt-to-Income Ratio (DIR) using imputed income and debt values\n",
    "data['DIR'] = data['debt_impute'] / data['income_impute']\n",
    "data['DIR'] = data['DIR'].replace([float('inf'), float('nan')], 0)  # Replace inf and NaN with 0\n",
    "\n",
    "\n",
    "data[['debt_impute', 'income_impute', 'DIR']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   adjusted_total_risk_score\n",
      "0                       11.5\n",
      "1                       32.5\n",
      "2                       29.5\n",
      "3                       39.0\n",
      "4                       19.5\n"
     ]
    }
   ],
   "source": [
    "# Define refined scores for each type of investment product\n",
    "refined_investment_scores = {\n",
    "    'etf': 10,\n",
    "    'stocks': 9,\n",
    "    'high return mutual fund': 8.5,\n",
    "    'segregated fund': 8,\n",
    "    'mutual fund': 7,\n",
    "    'rrsp': 6.5,\n",
    "    'tfsa': 6,\n",
    "    'ul policy': 5.5,\n",
    "    'mortgage investment': 5,\n",
    "    'annuity': 3,\n",
    "    'long term care insurance': 2.5,\n",
    "    'gic': 2,\n",
    "    'bond': 1.5,\n",
    "    'index linked gic': 1.2,\n",
    "    'repay debt': 1\n",
    "}\n",
    "\n",
    "# Define function to score each investment product based on text\n",
    "def refined_score_investment(text):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    for product, score in refined_investment_scores.items():\n",
    "        if product in text.lower():\n",
    "            return score\n",
    "    return 0\n",
    "\n",
    "# Define scenario and corresponding rate columns\n",
    "scenario_columns = ['scn1a_answer', 'scn2a_answer', 'scn3a_answer', 'scn4a_answer', 'scn1b_answer', 'scn2b_answer', 'scn3b_answer', 'scn4b_answer']\n",
    "rate_columns = ['scn1a_apr', 'scn1b_apr', 'scn2a_rate', 'scn2b_rate', 'scn3a_rate', 'scn3b_rate', 'scn4a_segfees', 'scn4b_segfees']\n",
    "\n",
    "# Apply the scoring function to each scenario column\n",
    "for col in scenario_columns:\n",
    "    data[f'{col}_refined_investment_score'] = data[col].apply(refined_score_investment)\n",
    "\n",
    "# Convert rate columns to numeric and fill any NaN values with 1 to avoid null multiplication\n",
    "data[rate_columns] = data[rate_columns].apply(pd.to_numeric, errors='coerce').fillna(1)\n",
    "\n",
    "# Calculate the adjusted score by multiplying each scenario score with its corresponding rate\n",
    "adjusted_scores = []\n",
    "for i in range(len(scenario_columns)):\n",
    "    score_col = f'{scenario_columns[i]}_refined_investment_score'\n",
    "    rate_col = rate_columns[i]\n",
    "    adjusted_scores.append(data[score_col] * data[rate_col])\n",
    "\n",
    "# Sum all adjusted scores to get the final adjusted_total_risk_score\n",
    "data['adjusted_total_risk_score'] = sum(adjusted_scores)\n",
    "\n",
    "# Preview the adjusted total risk score\n",
    "print(data[['adjusted_total_risk_score']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to all the answers from questionaire \"SECTION 2. SHOW THE FOLLOWING TITLE TO RESPONDENTS\", we refinined the calculation of the adjusted_total_risk_score by incorporating both the investment product scores and corresponding interest rates or fees for each scenario. This approach aims to produce a more nuanced risk score that reflects not only the type of investment recommended but also the associated rate, which can indicate additional risk elements.\n",
    "\n",
    "We assign scores to each investment product mentioned in the scenario responses based on their inherent risk levels. For instance, high-risk products like ETFs receive a higher score, while low-risk products like bonds receive a lower score.\n",
    "\n",
    "By multiplying each scenario’s investment product score with its corresponding rate (such as APR or fees), we create a weighted score. Higher rates typically indicate higher financial exposure or risk, so by treating the rate as a multiplier, we capture this aspect within the overall score.\n",
    "\n",
    "After calculating each scenario’s adjusted score (product score * rate), we sum all scenarios to yield the adjusted_total_risk_score. This final score now accounts for both the inherent risk of each investment type and the added risk implied by high rates or fees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## log-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIR</th>\n",
       "      <th>DIR_category</th>\n",
       "      <th>log_DIR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.272727</td>\n",
       "      <td>High</td>\n",
       "      <td>1.662550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>-11.512925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.538462</td>\n",
       "      <td>High</td>\n",
       "      <td>1.512590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>Low</td>\n",
       "      <td>-1.609388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>-11.512925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DIR DIR_category    log_DIR\n",
       "0  5.272727         High   1.662550\n",
       "1  0.000000          Low -11.512925\n",
       "2  4.538462         High   1.512590\n",
       "3  0.200000          Low  -1.609388\n",
       "4  0.000000          Low -11.512925"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Classify DIR into low, medium, high categories based on quantiles\n",
    "data['DIR_category'] = pd.qcut(data['DIR'], q=3, labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "# Apply log transformation to DIR, handling zeros by adding a small constant\n",
    "data['log_DIR'] = np.log(data['DIR'] + 1e-5)\n",
    "\n",
    "# Check the DIR categories and log-transformed DIR\n",
    "data[['DIR', 'DIR_category', 'log_DIR']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## control variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: Index(['respid', 'status', 'language', 'gender', 'age', 'province',\n",
      "       'license_mutualfunds', 'license_insurance', 'license_securities',\n",
      "       'educ',\n",
      "       ...\n",
      "       'scn2a_answer_refined_investment_score',\n",
      "       'scn3a_answer_refined_investment_score',\n",
      "       'scn4a_answer_refined_investment_score',\n",
      "       'scn1b_answer_refined_investment_score',\n",
      "       'scn2b_answer_refined_investment_score',\n",
      "       'scn3b_answer_refined_investment_score',\n",
      "       'scn4b_answer_refined_investment_score', 'adjusted_total_risk_score',\n",
      "       'DIR_category', 'log_DIR'],\n",
      "      dtype='object', length=215)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>work_experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>University certificate, diploma, degree above ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>Bachelor's degree (e.g. B.A., B.Sc., LL.B.)</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>Bachelor's degree (e.g. B.A., B.Sc., LL.B.)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41</td>\n",
       "      <td>Bachelor's degree (e.g. B.A., B.Sc., LL.B.)</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>University certificate or diploma below the ba...</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age                                               educ  work_experience\n",
       "0   26  University certificate, diploma, degree above ...              2.0\n",
       "1   47        Bachelor's degree (e.g. B.A., B.Sc., LL.B.)             20.0\n",
       "2   40        Bachelor's degree (e.g. B.A., B.Sc., LL.B.)              1.0\n",
       "3   41        Bachelor's degree (e.g. B.A., B.Sc., LL.B.)             16.0\n",
       "4   65  University certificate or diploma below the ba...             15.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if control variables are available\n",
    "control_variables = ['age', 'educ', 'work_experience']\n",
    "print(\"Available columns:\", data.columns)\n",
    "\n",
    "# Display control variables\n",
    "data[control_variables].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>educ</th>\n",
       "      <th>educ_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University certificate, diploma, degree above ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bachelor's degree (e.g. B.A., B.Sc., LL.B.)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bachelor's degree (e.g. B.A., B.Sc., LL.B.)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bachelor's degree (e.g. B.A., B.Sc., LL.B.)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>University certificate or diploma below the ba...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                educ  educ_level\n",
       "0  University certificate, diploma, degree above ...           7\n",
       "1        Bachelor's degree (e.g. B.A., B.Sc., LL.B.)           6\n",
       "2        Bachelor's degree (e.g. B.A., B.Sc., LL.B.)           6\n",
       "3        Bachelor's degree (e.g. B.A., B.Sc., LL.B.)           6\n",
       "4  University certificate or diploma below the ba...           5"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a mapping for the education levels\n",
    "education_mapping = {\n",
    "    'Less than high school diploma or its equivalent': 1,\n",
    "    'High school diploma or a high school equivalency certificate': 2,\n",
    "    'Trade certificate or diploma': 3,\n",
    "    'College, CEGEP or other non-university certificate or diploma (other than trades certificates or diplomas)': 4,\n",
    "    'University certificate or diploma below the bachelor\\'s level': 5,\n",
    "    'Bachelor\\'s degree (e.g. B.A., B.Sc., LL.B.)': 6,\n",
    "    'University certificate, diploma, degree above the bachelor\\'s level': 7\n",
    "}\n",
    "\n",
    "# Map the education levels in the data to the numeric values\n",
    "data['educ_level'] = data['educ'].map(education_mapping)\n",
    "\n",
    "# Check the transformed education levels\n",
    "data[['educ', 'educ_level']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Medium</th>\n",
       "      <th>High</th>\n",
       "      <th>log_DIR</th>\n",
       "      <th>debt</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>work_experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.662550</td>\n",
       "      <td>580000.0</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.512590</td>\n",
       "      <td>295000.0</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.609388</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Medium   High    log_DIR      debt  age  educ  work_experience\n",
       "0   False   True   1.662550  580000.0   26     7              2.0\n",
       "1   False  False -11.512925       0.0   47     6             20.0\n",
       "2   False   True   1.512590  295000.0   40     6              1.0\n",
       "3   False  False  -1.609388   30000.0   41     6             16.0\n",
       "4   False  False -11.512925       0.0   65     5             15.0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert DIR_category to dummy variables\n",
    "X = pd.get_dummies(data['DIR_category'], drop_first=True)  # Drop \"Low\" as baseline\n",
    "X['log_DIR'] = data['log_DIR']\n",
    "X['debt'] = data['debt']\n",
    "X['age'] = data['age']\n",
    "X['educ'] = data['educ_level']\n",
    "X['work_experience'] = data['work_experience']\n",
    "\n",
    "# Define dependent variable\n",
    "y = data['adjusted_total_risk_score']\n",
    "\n",
    "# Check the prepared variables for regression\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.560529\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            binary_risk   No. Observations:                  810\n",
      "Model:                          Logit   Df Residuals:                      802\n",
      "Method:                           MLE   Df Model:                            7\n",
      "Date:                 周六, 09 11月 2024   Pseudo R-squ.:                 0.01147\n",
      "Time:                        23:00:11   Log-Likelihood:                -454.03\n",
      "converged:                       True   LL-Null:                       -459.30\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1602\n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "const              -1.5408      0.668     -2.308      0.021      -2.849      -0.232\n",
      "Medium              0.5351      0.415      1.288      0.198      -0.279       1.349\n",
      "High                0.0789      0.490      0.161      0.872      -0.882       1.040\n",
      "log_DIR            -0.0632      0.038     -1.661      0.097      -0.138       0.011\n",
      "debt             6.439e-07   3.24e-07      1.990      0.047    9.83e-09    1.28e-06\n",
      "age                -0.0055      0.010     -0.542      0.588      -0.025       0.014\n",
      "educ                0.0504      0.064      0.791      0.429      -0.074       0.175\n",
      "work_experience    -0.0061      0.012     -0.504      0.614      -0.030       0.018\n",
      "===================================================================================\n"
     ]
    }
   ],
   "source": [
    "data['binary_risk'] = data['adjusted_total_risk_score'].apply(lambda x: 1 if x >= 28 else 0)\n",
    "y = data['binary_risk']\n",
    "\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "y = pd.to_numeric(y, errors='coerce')\n",
    "\n",
    "data_combined = pd.concat([X, y], axis=1).dropna().reset_index(drop=True)\n",
    "\n",
    "X = data_combined.drop(columns=['binary_risk'])\n",
    "y = data_combined['binary_risk']\n",
    "X = X.astype(float)\n",
    "y = y.astype(int)  \n",
    "X = sm.add_constant(X)\n",
    "\n",
    "logit_model = sm.Logit(y, X).fit()\n",
    "print(logit_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient for log_DIR is -0.0632 with a p-value of 0.097, indicating that this effect is close to being statistically significant. This suggests that, although the data does not provide strong evidence, there may still be a meaningful relationship between an analyst’s debt-to-income ratio and their risk tolerance. This trend could become more pronounced with additional data or could reflect behavioral tendencies in financially leveraged individuals.\n",
    "\n",
    "The coefficient for debt is very close to zero (6.439e-07), but its p-value of 0.047 suggests that it is statistically significant at the 5% level.Although the effect size appears small, statistical significance implies that absolute debt does indeed have an impact on the risk recommendation.\n",
    "\n",
    "Debt-to-Income Ratio may dilute the perception of financial burden, as it considers both debt and income. It could be that analysts, consciously or subconsciously, regard absolute debt as a more direct measure of financial risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIF TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance Inflation Factor (VIF):\n",
      "          Variable        VIF\n",
      "0            const  62.646212\n",
      "1           Medium   4.844218\n",
      "2             High   6.759587\n",
      "3          log_DIR   5.261611\n",
      "4             debt   1.842343\n",
      "5              age   2.251609\n",
      "6             educ   1.017195\n",
      "7  work_experience   2.212070\n",
      "Hosmer-Lemeshow Test:\n",
      "Chi-square: 5.926804828141834, p-value: 0.6554306642640263\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from scipy.stats import chi2\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "print(\"Variance Inflation Factor (VIF):\")\n",
    "print(vif_data)\n",
    "\n",
    "\n",
    "def hosmer_lemeshow_test(model, X, y, groups=10):\n",
    "    prob = model.predict(X)\n",
    "    data = pd.DataFrame({\"Observed\": y, \"Predicted\": prob})\n",
    "    data['Decile'] = pd.qcut(data['Predicted'], groups, labels=False)\n",
    "    hl_table = data.groupby('Decile').apply(lambda df: pd.Series({\n",
    "        'Obs_1': df['Observed'].sum(),\n",
    "        'Obs_0': (1 - df['Observed']).sum(),\n",
    "        'Pred_1': df['Predicted'].sum(),\n",
    "        'Pred_0': (1 - df['Predicted']).sum()\n",
    "    }))\n",
    "    hl_table['Chi_sq'] = (hl_table['Obs_1'] - hl_table['Pred_1']) ** 2 / hl_table['Pred_1'] + \\\n",
    "                         (hl_table['Obs_0'] - hl_table['Pred_0']) ** 2 / hl_table['Pred_0']\n",
    "    chi_sq = hl_table['Chi_sq'].sum()\n",
    "    p_value = 1 - chi2.cdf(chi_sq, groups - 2)\n",
    "    return chi_sq, p_value\n",
    "\n",
    "chi_sq, p_value = hosmer_lemeshow_test(logit_model, X, y)\n",
    "print(\"Hosmer-Lemeshow Test:\")\n",
    "print(f\"Chi-square: {chi_sq}, p-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "VIF Analysis: The VIF results indicate that there is no significant multicollinearity issue in the model, and the variables can be retained without concern for excessive correlation.\n",
    "\n",
    "Hosmer-Lemeshow Test: The model performs well in terms of binary logistic regression fit, suggesting that the model's ability to predict risk classification aligns well with the observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mean and standard deviation of all variables used in the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Variable           Mean  Standard Deviation\n",
      "0            const       1.000000            0.000000\n",
      "1           Medium       0.330864            0.470815\n",
      "2             High       0.328395            0.469920\n",
      "3          log_DIR      -2.735257            5.321379\n",
      "4             debt  248401.575309       322287.536357\n",
      "5              age      49.379012           11.993130\n",
      "6             educ       5.601235            1.323085\n",
      "7  work_experience      16.240741           10.044650\n",
      "8      binary_risk       0.237037            0.425528\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean and standard deviation of all variables used in the analysis\n",
    "# Assuming X and y are the variables used in the analysis\n",
    "variables_summary = pd.DataFrame()\n",
    "variables_summary['Mean'] = X.mean()\n",
    "variables_summary['Standard Deviation'] = X.std()\n",
    "variables_summary.loc['binary_risk', 'Mean'] = y.mean()\n",
    "variables_summary.loc['binary_risk', 'Standard Deviation'] = y.std()\n",
    "variables_summary = variables_summary.reset_index().rename(columns={'index': 'Variable'})\n",
    "print(variables_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our study aimed to examine how personal financial characteristics of financial analysts influence their risk recommendations. Specifically, we focused on two main variables:\n",
    "\n",
    "Debt-to-Income Ratio (DIR): Calculated as the ratio of an analyst’s total debt to their income, representing the relative financial pressure they may face.\n",
    "Absolute Debt Level: The total debt amount, which serves as a measure of the absolute financial burden without considering income.\n",
    "In addition, we analyzed other demographic and professional factors such as age, education level, and work experience, to understand their potential roles in shaping risk recommendation tendencies.\n",
    "\n",
    "Our findings suggest that personal financial status, specifically relative financial pressure (DIR) and absolute debt, may impact how financial analysts approach risk recommendations. Higher relative debt (DIR) appears to discourage high-risk recommendations, while higher absolute debt has the opposite effect, encouraging them to take on greater risk. This dual influence highlights the complex ways in which financial circumstances may affect professional decision-making in financial advising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Haotong Sun 11337172\n",
    "Generate AI used for coding assistance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
